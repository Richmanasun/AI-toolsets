{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b17fb3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "599c4009",
   "metadata": {},
   "source": [
    "前言\n",
    "时间序列数据，顾名思义，是一种随着时间改变的数据。例如，\n",
    "24小时气温数据，\n",
    "一个月的产品价格数据，\n",
    "某一公司股票价格年度数据。\n",
    "。。。。。。\n",
    "高级深度学习模型，比如长短期记忆网络（LSTM），能够捕获到时间序列数据中的变化模式，进而能够预测数据的未来趋势。本文中，我们将使用pytorch这个深度学习库，来实现利用LSTM算法对时间序列数据进行预测。\n",
    "\n",
    "在开始讲述之前，我们先导入必要的库，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "322928d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    " \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5004642e",
   "metadata": {},
   "source": [
    "数据集\n",
    "我们将使用Seaborn库的内建数据集。让我们打印一下Seaborn的所有内建数据库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7777666f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anagrams',\n",
       " 'anscombe',\n",
       " 'attention',\n",
       " 'brain_networks',\n",
       " 'car_crashes',\n",
       " 'diamonds',\n",
       " 'dots',\n",
       " 'dowjones',\n",
       " 'exercise',\n",
       " 'flights',\n",
       " 'fmri',\n",
       " 'geyser',\n",
       " 'glue',\n",
       " 'healthexp',\n",
       " 'iris',\n",
       " 'mpg',\n",
       " 'penguins',\n",
       " 'planets',\n",
       " 'seaice',\n",
       " 'taxis',\n",
       " 'tips',\n",
       " 'titanic']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.get_dataset_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04aa1ce",
   "metadata": {},
   "source": [
    "我们将使用flights数据集。可以用如下代码导入："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e88695aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949</td>\n",
       "      <td>Jan</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949</td>\n",
       "      <td>Feb</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1949</td>\n",
       "      <td>Mar</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1949</td>\n",
       "      <td>Apr</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1949</td>\n",
       "      <td>May</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year month  passengers\n",
       "0  1949   Jan         112\n",
       "1  1949   Feb         118\n",
       "2  1949   Mar         132\n",
       "3  1949   Apr         129\n",
       "4  1949   May         121"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_data = sns.load_dataset(\"flights\")\n",
    "flight_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f405b7",
   "metadata": {},
   "source": [
    "数据集有3列：年，月和乘客数量。乘客数量一列描述了单月内航班乘客总数。\n",
    "\n",
    "数据集的形状：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be908ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     year month  passengers\n",
      "0    1949   Jan         112\n",
      "1    1949   Feb         118\n",
      "2    1949   Mar         132\n",
      "3    1949   Apr         129\n",
      "4    1949   May         121\n",
      "..    ...   ...         ...\n",
      "139  1960   Aug         606\n",
      "140  1960   Sep         508\n",
      "141  1960   Oct         461\n",
      "142  1960   Nov         390\n",
      "143  1960   Dec         432\n",
      "\n",
      "[144 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(144, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(flight_data)\n",
    "flight_data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0442f4cc",
   "metadata": {},
   "source": [
    "可以看到，一共有144行和3列数据，即数据集包含12年的乘客记录。 我们的任务是利用前132个月的数据预测最后12个月乘客数。也就是说前132个月的数据用作训练，最后12个月的数据用作验证以评估模型。\n",
    "\n",
    "让我们来绘制每个月乘客出行的频率，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646b5573",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 15\n",
    "fig_size[1] = 5\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    " \n",
    "plt.title('Month vs Passenger')\n",
    "plt.ylabel('Total Passengers')\n",
    "plt.xlabel('Months')\n",
    "plt.grid(True)\n",
    "plt.autoscale(axis='x',tight=True)\n",
    "plt.plot(flight_data['passengers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc41e19",
   "metadata": {},
   "source": [
    "如图所示，多年来，乘飞机旅行的平均人数增加了。一年内旅行的乘客数量是波动的，这是有道理的，因为在夏季或冬季休假期间，旅行的乘客数量比一年中的其他时间增加。\n",
    "\n",
    "构建LSTM需要的样本集\n",
    "我们先看一下数据列中数据的类型，　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eec8d25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 144 entries, 0 to 143\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   year        144 non-null    int64   \n",
      " 1   month       144 non-null    category\n",
      " 2   passengers  144 non-null    int64   \n",
      "dtypes: category(1), int64(2)\n",
      "memory usage: 2.9 KB\n"
     ]
    }
   ],
   "source": [
    "flight_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f42dc73",
   "metadata": {},
   "source": [
    " 数据处理的第一步是将乘客数量一列的数据类型转换为float，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6974ca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = flight_data['passengers'].values.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568e232f",
   "metadata": {},
   "source": [
    "现在，如果你打印all_data这个numpy数组，你应该看到以下float类型的值。　　"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e4e748",
   "metadata": {},
   "source": [
    "接下来，我们将把我们的数据集分为训练集和测试集。LSTM算法将在训练集上进行训练。然后，该模型将被用来对测试集进行预测。预测结果将与测试集的实际值进行比较，以评估训练模型的性能。前132条记录将被用来训练模型，最后12条记录将被用作测试集。下面的代码将数据分为训练集和测试集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d012b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_size = 12\n",
    " \n",
    "train_data = all_data[:-test_data_size]\n",
    "test_data = all_data[-test_data_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af18d6b0",
   "metadata": {},
   "source": [
    "让我们打印一下训练集和测试集的样本个数："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d86a323",
   "metadata": {},
   "source": [
    "我们的数据集目前还没有被归一化（normalization）。最初几年的乘客总数与后来几年的乘客总数相比要少得多。对于时间序列预测来说，将数据归一化是非常重要的。我们将对数据集进行最小/最大缩放，使数据在一定的最小值和最大值范围内归一化。我们将使用sklearn.preprocessing模块中的MinMaxScaler类来缩放我们的数据。下面的代码使用最小/最大缩放器对我们的数据进行归一化处理，最小值和最大值分别为-1和1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aecafb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    " \n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train_data_normalized = scaler.fit_transform(train_data .reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fbde8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_normalized = torch.FloatTensor(train_data_normalized).view(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb9cad5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_window = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f00dbf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = input_data[i:i+tw]\n",
    "        train_label = input_data[i+tw:i+tw+1]\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return inout_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f8f511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inout_seq = create_inout_sequences(train_data_normalized, train_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35d12815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([-0.9648, -0.9385, -0.8769, -0.8901, -0.9253, -0.8637, -0.8066, -0.8066,\n",
       "          -0.8593, -0.9341, -1.0000, -0.9385]),\n",
       "  tensor([-0.9516])),\n",
       " (tensor([-0.9385, -0.8769, -0.8901, -0.9253, -0.8637, -0.8066, -0.8066, -0.8593,\n",
       "          -0.9341, -1.0000, -0.9385, -0.9516]),\n",
       "  tensor([-0.9033])),\n",
       " (tensor([-0.8769, -0.8901, -0.9253, -0.8637, -0.8066, -0.8066, -0.8593, -0.9341,\n",
       "          -1.0000, -0.9385, -0.9516, -0.9033]),\n",
       "  tensor([-0.8374])),\n",
       " (tensor([-0.8901, -0.9253, -0.8637, -0.8066, -0.8066, -0.8593, -0.9341, -1.0000,\n",
       "          -0.9385, -0.9516, -0.9033, -0.8374]),\n",
       "  tensor([-0.8637])),\n",
       " (tensor([-0.9253, -0.8637, -0.8066, -0.8066, -0.8593, -0.9341, -1.0000, -0.9385,\n",
       "          -0.9516, -0.9033, -0.8374, -0.8637]),\n",
       "  tensor([-0.9077]))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inout_seq[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7adace74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self,input_size=1,hidden_layer_size=100,output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size,hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size,output_size)\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),torch.zeros(1,1,self.hidden_layer_size))\n",
    " \n",
    "    def forward(self,input_seq):\n",
    "        lstm_out,self.hidden_cell = self.lstm(input_seq.view(len(input_seq),1,-1), self.hidden_cell)\n",
    "        predictions.shape:[L,1]\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        predictions[-1].shape:[1]\n",
    "        return predictions[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cdc63a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM()\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0142be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(1, 100)\n",
      "  (linear): Linear(in_features=100, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8f18c78",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'predictions' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_60976/423477081.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                         torch.zeros(1, 1, model.hidden_layer_size))\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0msingle_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_60976/2640621755.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_seq)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_cell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'predictions' referenced before assignment"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    " \n",
    "for i in range(epochs):\n",
    "    for seq, labels in train_inout_seq:\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                        torch.zeros(1, 1, model.hidden_layer_size))\n",
    " \n",
    "        y_pred = model(seq)\n",
    " \n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "        \n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c4b5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5c5c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3e2b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, batch_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.num_directions = 1 # 单向LSTM\n",
    "        self.batch_size = batch_size\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        h_0 = torch.randn(self.num_directions * self.num_layers, self.batch_size, self.hidden_size).to(device)\n",
    "        c_0 = torch.randn(self.num_directions * self.num_layers, self.batch_size, self.hidden_size).to(device)\n",
    "        seq_len = input_seq.shape[1] # (5, 30)\n",
    "        # input(batch_size, seq_len, input_size)\n",
    "        input_seq = input_seq.view(self.batch_size, seq_len, 1)  # (5, 30, 1)\n",
    "        # output(batch_size, seq_len, num_directions * hidden_size)\n",
    "        output, _ = self.lstm(input_seq, (h_0, c_0)) # output(5, 30, 64)\n",
    "        output = output.contiguous().view(self.batch_size * seq_len, self.hidden_size) # (5 * 30, 64)\n",
    "        pred = self.linear(output) # pred(150, 1)\n",
    "        pred = pred.view(self.batch_size, seq_len, -1) # (5, 30, 1)\n",
    "        pred = pred[:, -1, :]  # (5, 1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2602c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, batch_first=True)\n",
    "self.linear = nn.Linear(self.hidden_size, self.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e1c54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "我们加上具体的数字："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54bf465",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.lstm = nn.LSTM(self.input_size=1, self.hidden_size=64, self.num_layers=5, batch_first=True)\n",
    "self.linear = nn.Linear(self.hidden_size=64, self.output_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fdcf1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59e2bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf8faff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90260cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385677f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3f506a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
