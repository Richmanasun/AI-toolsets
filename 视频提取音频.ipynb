{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4c98cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asun\\AppData\\Roaming\\Python\\Python311\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in output.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "发生错误： recognition request failed: Bad Request\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    " \n",
    "# 定义函数将视频转换为音频并保存到本地\n",
    "def video_to_audio(video_path):\n",
    "    # 导入视频处理模块（这里使用ffmpeg）\n",
    "    from moviepy.editor import VideoFileClip\n",
    "    \n",
    "    # 提取视频中的音频部分\n",
    "    audio = VideoFileClip(video_path).audio\n",
    "    \n",
    "    # 设置输出音频格式及路径\n",
    "    output_file = \"output.wav\"\n",
    "    \n",
    "    # 保存音频到本地\n",
    "    audio.write_audiofile(output_file)\n",
    "    \n",
    "    return output_file\n",
    " \n",
    "# 加载音频文件\n",
    "audio_file = video_to_audio(\"2024-01-08 14-02-35.mkv\")\n",
    " \n",
    "# 创建Recognizer对象\n",
    "r = sr.Recognizer()\n",
    " \n",
    "# 打开音频文件\n",
    "with sr.AudioFile(audio_file) as source:\n",
    "    # 从音频文件中获取音频流\n",
    "    audio = r.record(source) \n",
    "try:\n",
    "    # 使用Google Web Speech API进行语音识别\n",
    "    text = r.recognize_google(audio, language='zh-CN')\n",
    "    print('转换结果：', text)\n",
    "except Exception as e:\n",
    "    print('发生错误：', str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eac6d9ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m audio_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwozouhou.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# 打开音频文件\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msr\u001b[49m\u001b[38;5;241m.\u001b[39mAudioFile(audio_file) \u001b[38;5;28;01mas\u001b[39;00m source:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# 从音频文件中获取音频流\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     audio \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mrecord(source) \n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# 使用Google Web Speech API进行语音识别\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sr' is not defined"
     ]
    }
   ],
   "source": [
    "audio_file = \"wozouhou.wav\"\n",
    "# 打开音频文件\n",
    "with sr.AudioFile(audio_file) as source:\n",
    "    # 从音频文件中获取音频流\n",
    "    audio = r.record(source) \n",
    "try:\n",
    "    # 使用Google Web Speech API进行语音识别\n",
    "    text = r.recognize_google(audio, language='zh-CN')\n",
    "    print('转换结果：', text)\n",
    "except Exception as e:\n",
    "    print('发生错误：', str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e378b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len: 218\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Given audio file must be a filename string or a file-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunks[i]) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2000\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunks[i]) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000000\u001b[39m:\n\u001b[0;32m     35\u001b[0m         chunks\u001b[38;5;241m.\u001b[39mpop(i)\n\u001b[1;32m---> 36\u001b[0m         \u001b[43mtrans_google\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m取有效分段(大于1s小于1000s)：\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(chunks))\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03mfor x in range(0,int(len(sound)/1000)):\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m    print(x,sound[x*1000:(x+1)*1000].max_dBFS)\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m, in \u001b[0;36mtrans_google\u001b[1;34m(audiosources)\u001b[0m\n\u001b[0;32m      2\u001b[0m audio_file \u001b[38;5;241m=\u001b[39m audiosources\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 打开音频文件\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAudioFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m source:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# 从音频文件中获取音频流\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     audio \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mrecord(source) \n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# 使用Google Web Speech API进行语音识别\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\speech_recognition\\__init__.py:226\u001b[0m, in \u001b[0;36mAudioFile.__init__\u001b[1;34m(self, filename_or_fileobject)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_fileobject):\n\u001b[1;32m--> 226\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filename_or_fileobject, (\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename_or_fileobject, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGiven audio file must be a filename string or a file-like object\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename_or_fileobject \u001b[38;5;241m=\u001b[39m filename_or_fileobject\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Given audio file must be a filename string or a file-like object"
     ]
    }
   ],
   "source": [
    "def trans_google(audiosources):\n",
    "    audio_file = audiosources\n",
    "    # 打开音频文件\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        # 从音频文件中获取音频流\n",
    "        audio = r.record(source) \n",
    "    try:\n",
    "        # 使用Google Web Speech API进行语音识别\n",
    "        text = r.recognize_google(audio, language='zh-CN')\n",
    "        print('转换结果：', text)\n",
    "    except Exception as e:\n",
    "        print('发生错误：', str(e))\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    " \n",
    "sound = AudioSegment.from_mp3(\"output.wav\")\n",
    "loudness = sound.dBFS\n",
    "#print(loudness)\n",
    " \n",
    "chunks = split_on_silence(sound,\n",
    "    # must be silent for at least half a second,沉默半秒\n",
    "    min_silence_len=430,\n",
    " \n",
    "    # consider it silent if quieter than -16 dBFS\n",
    "    silence_thresh=-45,\n",
    "    keep_silence=400\n",
    " \n",
    ")\n",
    "print('Len:', len(chunks))\n",
    " \n",
    "# 放弃长度小于2秒的录音片段\n",
    "for i in list(range(len(chunks)))[::-1]:\n",
    "    if len(chunks[i]) <= 2000 or len(chunks[i]) >= 1000000:\n",
    "        chunks.pop(i)\n",
    "        trans_google(chunks[i])\n",
    "        \n",
    "print('取有效分段(大于1s小于1000s)：', len(chunks))\n",
    " \n",
    "'''\n",
    "for x in range(0,int(len(sound)/1000)):\n",
    "    print(x,sound[x*1000:(x+1)*1000].max_dBFS)\n",
    "'''\n",
    " \n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk.export(\"wozouhou_{0}.wav\".format(i), format=\"wav\")\n",
    "    #print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88f905a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something!\n",
      "Google Speech Recognition thinks you said in English: -  hello\n",
      "Google Speech Recognition thinks you said in Turkish: -  Hello\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# obtain audio from the microphone\n",
    "r = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "\tprint(\"Say something!\")\n",
    "\taudio = r.listen(source)\n",
    "\n",
    "# recognize speech using Google Speech Recognition\n",
    "try:\n",
    "\t# for testing purposes, we're just using the default API key\n",
    "\t# to use another API key, use `r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\")`\n",
    "\t# instead of `r.recognize_google(audio)`\n",
    "\tprint(\"Google Speech Recognition thinks you said in English: -  \" + r.recognize_google(audio, language = \"en-US\"))\n",
    "\tprint(\"Google Speech Recognition thinks you said in Turkish: -  \" + r.recognize_google(audio, language = \"tr-TR\"))\n",
    "except sr.UnknownValueError:\n",
    "\tprint(\"Google Speech Recognition could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "\tprint(\"Could not request results from Google Speech Recognition service; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a098f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "发生错误： recognition request failed: Bad Request\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "# 创建Recognizer对象\n",
    "r = sr.Recognizer()\n",
    "audio_file = \"wozouhou.wav\"\n",
    "# 打开音频文件\n",
    "with sr.AudioFile(audio_file) as source:\n",
    "    # 从音频文件中获取音频流\n",
    "    audio = r.record(source) \n",
    "try:\n",
    "    # 使用Google Web Speech API进行语音识别\n",
    "    text = r.recognize_google(audio, language='zh-CN')\n",
    "    print('转换结果：', text)\n",
    "except Exception as e:\n",
    "    print('发生错误：', str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6a8054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "audio_file = '20220921_110131.wav'\n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile(audio_file) as source:\n",
    "    audio = r.record(source)\n",
    "try:\n",
    "    print('文本内容：',r.recognize_sphinx(audio,language = \"zh-CN\"))\n",
    "    #print('文本内容：', r.recognize_sphinx(audio))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef866774",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
